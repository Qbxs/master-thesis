\chapter{Type System}
\label{ch:type-system}
% explain type inference with algebraic subtyping/bounds/bisubstitutions

\section{Typing Rules}

\begin{figure}[h]
    \begin{center}
        \AxiomC{}
        \RightLabel{\textsc{T-Singleton}}
        \UnaryInfC{$\ctx 0 : \Singleton{0}, 1 : \Singleton{1}, \dots$}
        \DisplayProof

        {\vskip.2in}

        \AxiomC{}
        \RightLabel{\textsc{T-String}}
        \UnaryInfC{$\ctx "[a-zA-Z]^*" : \mathit{String}$}
        \DisplayProof

        {\vskip.2in}

        \AxiomC{}
        \RightLabel{\textsc{T-Var}}
        \UnaryInfC{$\Gamma, x : \tau \vdash x : \tau$}
        \DisplayProof
        {\hskip.2in}
        \AxiomC{$\ctx e_1 : \sigma \to \tau$}
        \AxiomC{$\ctx e_2 : \sigma$}
        \RightLabel{\textsc{T-App}}
        \BinaryInfC{$\ctx e_1 \; e_2 : \tau$}
        \DisplayProof

        {\vskip.2in}

        \AxiomC{$\Gamma, x : \sigma \vdash e : \tau$}
        \RightLabel{\textsc{T-Abs}}
        \UnaryInfC{$\ctx \lambda x.e : \sigma \to \tau$}
        \DisplayProof
        {\hskip.2in}
        \AxiomC{$\ctx e : \sigma$}
        \AxiomC{$\sigma \sub \tau$}
        \RightLabel{\textsc{T-Sub}}
        \BinaryInfC{$\ctx e : \tau$}
        \DisplayProof
    \end{center}
    \caption{Typing Rules}
    \label{fig:typing-rules}
\end{figure}

The resolution rules for type class witnesses in section \ref{sec:witnesses} provide us with means to implement type checking for type class methods.
For every call to a type class method resolution either fails or provides a dictionary, i.e. a witness, for the type class constraint.

For simplicity, we annotate calls of type class methods with types.
These types will be used to resolve a suitable instance.
Omitting type annotations, poses some additional challenges as discussed in further work.

What makes this kind of typing derivation special is that it not only decomposes judgements upwards,
but fills in the hole displayed by the type class constraint downwards by resolving a fitting witness.
This resolved hole stands for the concrete witness that will be passed to the type class method for evaluation.

Type inference for type class method calls (fig. \ref{fig:showable-example}):
$w$ is the implicit witness for the type class constraint $\Showable(\tau)$ which is inferred by type class resolution and $\tau$ is the annotated type.
$k$ is the continuation that is passed to the type class method.

Generally we generate constraints between the types introduced in the class declaration of the method and the unification variables generated for its arguments.
In this case $\mathbf{show}$ is implemented in continuation passing style, so apart from the argument to be shown $x$, there is continutation $k$ which consumes the $\mathit{String}$ output.
The argument $w$ is implicit and stands for the inferred witness of the type class.
At compilation it will be filled with a resolved instance, so that the evaluation of the metod is well defined.

\begin{figure}[h]
    \centering
    \AxiomC{$\ctx w : \Showable(\tau)$}
    \AxiomC{$\ctx x : \tau$}
    \AxiomC{$\ctx k : \String \to \sigma$}
    \RightLabel{\textsc{T-Class}$^+$}
    \TrinaryInfC{$\ctx \showTerm [\tau] w \; x \; k : \sigma$}
    \DisplayProof
    \caption{Derivation for $\showTerm w \; x \; k : \sigma$}
    \label{fig:showable-example}
\end{figure}

For contravariant type classes such as $\Readable$ the inference looks slightly different:
In this case, the type class constraint is applied to the argument type of the continuation.

\begin{figure}[h]
    \centering
    \AxiomC{$\ctx w : \Readable(\tau)$}
    \AxiomC{$\ctx x : \String$}
    \AxiomC{$\ctx k : \tau \to \sigma$}
    \RightLabel{\textsc{T-Class}$^-$}
    \TrinaryInfC{$\ctx \readTerm [\tau] w \; x \; k : \sigma$}
    \DisplayProof
    \caption{Derivation for $\readTerm w \; x \; k : \sigma$}
    \label{fig:readable-example}
\end{figure}

We use a simplified notion here by requiring type annotations for type class method calls.
Therefore, no fresh variables will be generated at this point.
Instead, we use the annotated type to resolve a fitting instance for the type class constraint.
In section (TODO) we discuss why generating fresh unification variables at this point is challenging.

Outlined below is the algorithm used to infer a principle(?) type for any given term without the presence of type classes.
We will then examine, which alterations need to be done in order to achieve the same with the addition of type class constraints.

\section{Type Inference}
\label{sec:type-inference}

The core of type inference is done using a biunifaction algorithm which keeps track of lower and upper bounds for each unification variable.
For this, in the first step, we generate subtyping and type class constraints based on the term.
When solving the constraint set, the algorithm either fails (i.e. the term does not type check) or for all unification variables we obtain lower and upper bounds, as well as type class constraints.
The resulting bisubstitution is used to compute a principal type which can later be simplified using a translation to its type automata representation which is being minimized.
As a result, we obtain a simple principal type for any term that typechecks.

\subsection{Constraint Generation}

We generate constraints in a constraint set for each term. (Fig. \ref{fig:constraint-generation})


% do we need this? no
\begin{figure}[h]
    \begin{center}
        $\constraintGen{\alpha}_\tau^\bot := \alpha$ \\
        $\constraintGen{\alpha}_\tau^\top := \alpha$ \\
        $\constraintGen{\nu \to \nu'}_\tau^\bot := \constraintGen{\nu}_\tau^\top \to \constraintGen{\nu'}_\tau^\bot$ \\
        $\constraintGen{\nu \to \nu'}_\tau^\top := \constraintGen{\nu}_\tau^\bot \to \constraintGen{\nu'}_\tau^\top$ \\
        $\constraintGen{\mu\alpha.\nu}_\tau^\bot := \mu\alpha.\constraintGen{\nu}_\tau^\bot$ \\
        $\constraintGen{\mu\alpha.\nu}_\tau^\top := \mu\alpha.\constraintGen{\nu}_\tau^\top$ \\
    \end{center}
    \caption{Upper/lower bound translation}
    \label{fig:bound-translation}
\end{figure}

\begin{figure}[h]
    \begin{center}

        \AxiomC{$\Gamma(x) = \tau$}
        \RightLabel{\textsc{Var}}
        \UnaryInfC{$\Gamma \vdash x : \tau \toConstr \emptyset$}
        \DisplayProof

        {\vskip.1in}

        \AxiomC{$\Gamma \vdash e : \tau \toConstr \Xi$}
        \AxiomC{$\mathit{Fresh}(\beta)$}
        \RightLabel{\textsc{Lam}}
        \BinaryInfC{$\Gamma \vdash \lambda x. e : \beta \to \tau \toConstr \Xi$}
        \DisplayProof

        {\vskip.1in}

        \AxiomC{$\Gamma \vdash e_1 : \sigma_1 \toConstr \Xi_1$}
        \AxiomC{$\Gamma \vdash e_2 : \sigma_2 \toConstr \Xi_2$}
        \AxiomC{$\mathit{Fresh}(\beta)$}
        \RightLabel{\textsc{App}}
        \TrinaryInfC{$\Gamma \vdash e_1e_2 : \beta \toConstr \{ \sigma_1 \sub \sigma_2 \to \beta \} \cup \Xi_1 \cup \Xi_2$}
        \DisplayProof

        {\vskip.1in}

        \AxiomC{$\Gamma \vdash x : \sigma \toConstr \Xi$}
        \AxiomC{$P(\mathbf{m}) := \forall \alpha. \Phi(\alpha) \Rightarrow \alpha \to \rho$}
        \RightLabel{\textsc{Method}$^+$}
        \BinaryInfC{$\Gamma \vdash \mathbf{m} [\beta] \; x : \tau \toConstr \{ \Phi_m(\beta), \sigma \sub \beta, \tau \sub \rho \} \cup \Xi$}
        \DisplayProof

        {\vskip.1in}

        \AxiomC{$\Gamma \vdash x : \sigma \toConstr \Xi$}
        \AxiomC{$P(\mathbf{m}) := \forall \alpha. \Phi(\alpha) \Rightarrow \rho \to \alpha$}
        \RightLabel{\textsc{Method}$^-$}
        \BinaryInfC{$\Gamma \vdash \mathbf{m} [\beta] \; x : \tau \toConstr \{ \Phi_m(\beta), \beta \sub \tau, \sigma \sub \rho \} \cup \Xi$}
        \DisplayProof

    \end{center}
    \caption{Constraint Generation}
    \label{fig:constraint-generation}
\end{figure}

\subsection{Constraint Solving}

Constraints are solved by decomposition into simpler constraints. (Fig. \ref{fig:constraint-decomposition})
Simple constraints will be added to the lower and upper bounds of unification variables.
Constraints which cannot be solved (e.g. $\Nat \sub \Nat \to \bot$) lead to an error, thus type inference for the term fails, as expected.

\begin{figure}[h]
    \begin{center}
        placeholder: rules for solvinf constraints
        \begin{itemize}
            \item cache hits
            \item adding to lower/upper bounds
            \item decomposing
            \item fail
        \end{itemize}
    \end{center}
    \caption{Constraint Solving}
    \label{fig:constraint-solving}
\end{figure}

\begin{figure}[h]
    % We might add witnesses here?
    \begin{flalign*}
        \decompose{\tau}{\top}                               & := & \emptyset                                         \\
        \decompose{\bot}{\tau}                               & := & \emptyset                                         \\
        \decompose{\tau_1 \join \tau_2}{\sigma}              & := & \{ \tau_1 \sub \sigma, \tau_2 \sub \sigma \}      \\
        \decompose{\sigma}{\tau_1 \meet \tau_2}              & := & \{ \sigma \sub \tau_1, \sigma \sub \tau_2 \}      \\
        \decompose{\tau}{\mu\alpha.\sigma}                   & := & \{ \tau \sub \sigma[\mu\alpha.\sigma / \alpha] \} \\
        \decompose{\mu\alpha.\sigma}{\tau}                   & := & \{ \sigma[\mu\alpha.\sigma / \alpha] \sub \tau \} \\
        \decompose{\alpha}{\alpha}                           & := & \emptyset                                         \\
        \decompose{\sigma_1 \to \tau_1}{\sigma_2 \to \tau_2} & := & \{ \sigma_2 \sub \sigma_1, \tau_1 \sub \tau_2 \}  \\
    \end{flalign*}
    \caption{Constraint Decomposition}
    \label{fig:constraint-decomposition}
\end{figure}

\subsection{Type Coalescing}

The upper and lower bounds of unification variables are being coalesced to preserve transitivity of the subtyping relation and reduce the number of constraints of the inferred type.
E.g. if $\alpha$ has the upper bound $\beta$ and $\beta$ has the upper bound $\Nat$, we can coalesce the bounds and deduce that $\alpha$ also has $\Nat$ as an upper bound.

\subsection{Type Simplification}

After type coalescing we are not yet done in inferring a principle type, as in many cases there are additional simplification steps possible.
E.g. \dots

As Dolan has shown \cite{dolan2017subtyping} types can be translated into type automata, a disinguished form of finite state automata.
This enables us to use all known algorithm that operate on finite state automata on types, especially determinisation and minimisation.

\subsubsection{Constrained Nodes}

As an expansion for type automata we introduced constrained nodes.
Any node can now be annotated by a set of type classes representing type class constraints.
With this addition we have to consider how to merge nodes, as simplification should not impose any additional constraints.

\subsection{Emptiness Check}

Dolan \cite{downen2017phd} has shown how we can translate types to type automata in order to simplify inferred types.
These type automata are a form of finite automata, so all the standard algorithms for finite automata (such as determinisation, minimisation) can be performed on them.
Originally, this strategy was used to syntactically simplify inferred types but it opens up other possibilities.

By translating types for which we want to check for an overlap, we can construct an intersection automaton using the standard algorithm for intersections of finite automata.
All that is left to do from there, is to check whether the resulting automaton accepts the empty language,  i.e. no final state is reachable from the start state.\
The following outlines how this achieved:

\begin{figure}
  \centering
  \begin{tikzpicture}[node distance={25mm}, main/.style = {draw, circle}]
    \node[main] (1) {$\to$};
    \node[main] (2) [below left of=1] {$\Singleton{0}$};
    \node[main] (3) [below right of=1] {$\to$};
    \node[main] (4) [below left of=3] {$\Nat$};
    \node[main] (5) [below right of=3] {$\Nat$};
    \draw[->] (1) edge["l"] (2);
    \draw[->] (1) edge["r"] (3);
    \draw[->] (3) edge["l"] (4);
    \draw[->] (3) edge["r"] (5);
  \end{tikzpicture}
  \caption{Type automaton for $\Singleton{0} \to (\Nat \to \Nat)$}
  \label{fig:example-type-automaton}
\end{figure}

\begin{itemize}
  \item We create a type automaton $G = (q_0, N, E, \delta)$
  \item We construct the intersection automaton as $G_\cap = \dots$
  \item We check whether $G_\cap$ accepts the empty language, i.e. represents the empty type $\bot$
\end{itemize}

\subsubsection{Constructing type automata}
\subsubsection{Minimizing type automata}


\subsection{Rest}
We should always check in an instance declaration whether this constraint globally holds. \\
To guarantee modularity we also have to check this for module imports, but since even the import of functions using different instances for the same type can lead to incoherences, we have to rule out any declaration of orphan instances.
\cite{Kilpatrick2019-cy}.