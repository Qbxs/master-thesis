\chapter{Polymorphism}\label{ch:polymorphism}

Polymorphism is a general concept in programming languages to abstract code and hide implementation details.
In order to generalize functions over data types there have been several proposals to abstract over types in different programming languages:
These can be summarised in three categories: parametric polymorphism, subtyping and ad-hoc polymorphism.
Each of these have a reasoning principle associated with them.
In this chapter, we want to examine the different forms of polymorphism and how mixing them affects our ability to reason about them.

\section{Parametric polymorphism}\label{sec:parmetric-polymorphism}

Parametric polymorphism is used in many functional languages but has been adopted as well in common main stream languages like Java.
Using this feature, we ce can define functions without knowing the concrete representation of the arguments and result types.
We can therefore implement abstract algorithms detached from concrete type representation.
For example the universal identity function is typeable with $\mathbf{id} : \forall \alpha. \alpha \to \alpha$.

This form of polymorphism allows us furthermore to reason about the behavior of functions:
The $\mathbf{id}$ function mentioned above can only be implemented in one way:

$$
\mathbf{id} := \lambda x.x
$$

Its type enables us only to simply return the argument, because without knowing its type there is nothing else we could do with it.
Similarily, for a function $\mathbf{g} : \forall \alpha. \alpha \to \alpha \to \alpha$ there can be at most two implementations:
One that returns the first and one that returns the second argument.

More interesting, perhaps, is the usage of parametric data structures such as lists.
Given a function of type $\forall \alpha \beta. (\alpha \to \beta) \to \mathit{List } \alpha \to \mathit{List } \beta$, we expect this function to be the $\mathit{map}$ function which simply applies a supplied function to each element of a list and returns the transformed list.
Based on the type we can be sure that the supplied function $f$ is applied exactly once to each element of the list, as this is the only way to transform an element of type $\alpha$ to type $\beta$.
The only other possibilies are dropping and/or rearranging elements of the list but these are not typically expected here and in our type system it is impossible to refine the type of a function so much that it can only be implemented as $\mathit{map}$.

Many such \emph{theorems for free} can be derived using parametric polymorphism, as Wadler has shown. \cite{wadlertheorems}
This is especially useful for combining functions.
E.g. we can do optimizations based solely on the type of functions.
Given
$$\mathbf{head}  : \forall \alpha. \mathit{List } \alpha \to \alpha$$
$$\mathbf{map} : \forall \alpha \beta. (\alpha \to \beta) \to \mathit{List } \alpha \to \mathit{List } \beta$$
we can deduce that: $$\mathbf{head} \circ \mathbf{map} f = f \circ \mathbf{head}$$
Whereas the latter is more efficient due to it operating in constant rather than linear time complexity.

\section{Subtyping}\label{sec:subtyping}

In many cases the specific semantics of types exhibit a hierarchy.
Some types are more general versions of others and may encapsulate them.
This is typically expressed as a \emph{"is-a"} relationship, i.e. terms of one type are also terms of another type.

In Object-oriented programming this hierarchy is given in the form of sub- and superclasses.
We can express the relationship between super- and subclasses, or more generally super- and subtypes,
in the form that all properties of the superclass is also exhibited in the subclass. \cite{subtyping}

In the case of OO-languages this means that, if the class $\mathit{SubC}$ is a subclass of $\mathit{SuperC}$,
then any method defined in $\mathit{SuperC}$ is also going to be defined for objects of $\mathit{SubC}$.
This enables us to use an object $\mathit{SubC}$ wherever a $\mathit{SuperC}$ is expected.

We denote $\tau \sub \sigma$ for $\tau$ is a subtype of $\sigma$.
Syntactically, this implies that if we have obatined the judgement $e : \tau$, we also have $e : \sigma$.
Therefore, we can use $e$ in any context that expects the usage of a term of type $\sigma$.
Semantically, the subtyping relation can be understood analogously to sets in terms of the subset relationship $\subseteq$,
meaning all terms $e$ of type $\tau$ are also of type $\sigma$.
\cite{reynolds_1998}

This permits many useful features in programming languages such as the reuse and abstraction of code to the supertypes and implicit coercions from a subtype to a supertype.


We use the following syntax of types with the simple types of natural numbers $\Nat$, of integers $\Int$, the type of booleans $\Bool$ and the unit type $\Unit$.
Additionally, we introduce the singleton types $\Singleton{0}, \Singleton{1}, \Singleton{2}, \dots$ which are inhabited by exactly one value respectively, e.g. $1 : \Singleton{1}$.
Furthermore, for subtyping we consider the lattice types constructed by $\top, \bot, \meet, \join$:

\begin{figure}[h]
\begin{flalign*}
  ts          := & \; \forall \alpha_1 \dots \alpha_n. \tau                                 & \textit{Type schemes} \\
  \tau,\sigma := & \; \Nat \; | \; \Int \; | \; \Bool \; | \; \Unit \; | \; \String         & \textit{Simple types} \\
                 & \; \Singleton{0} \; | \; \Singleton{1} \; | \; \Singleton{2} \; | \dots  & \textit{Singleton types} \\
                 & \; \top \; | \; \bot \; | \; \tau \meet \sigma \; | \; \tau \join \sigma & \textit{Lattice types} \\
                 & \; \tau \to \sigma                                                       & \textit{Function types} \\
                 & \; \mu\alpha.\tau                                                        & \textit{Recursive types} \\
                 & \; \alpha                                                                & \textit{Recursive type variables}
\end{flalign*}
\label{fig:type-syntax}
\caption{The syntax of types}
\end{figure}

The subtyping lattice is defined by the following derivation rules where $\tau$, $\sigma$ and $\rho$ are meta variables for types.

% elim rules are derivable
\begin{figure}[h]
  % refl
  \begin{prooftree}
    \AxiomC{}
    \RightLabel{\textsc{Refl}}
    \UnaryInfC{$\tau \sub \tau$}
  \end{prooftree}

  % trans
  \begin{prooftree}
    \AxiomC{$\tau \sub \sigma$}
    \AxiomC{$\sigma \sub \rho$}
    \RightLabel{\textsc{Trans}}
    \BinaryInfC{$\tau \sub \rho$}
  \end{prooftree}

  % top/bot
 \begin{center}
  \AxiomC{}
  \RightLabel{\textsc{Top}}
  \UnaryInfC{$\tau \sub \top$}
  \DisplayProof
  {\hskip.2in}
  \AxiomC{}
  \RightLabel{\textsc{Bot}}
  \UnaryInfC{$\bot \sub \tau$}
  \DisplayProof
\end{center}

 % join intro
 \begin{center}
    \AxiomC{$\tau \sub \sigma$}
    \RightLabel{\textsc{JoinI}$_1$}
    \UnaryInfC{$\tau \sub \sigma \join \rho$}
    \DisplayProof
    {\hskip.2in}
    \AxiomC{$\tau \sub \sigma$}
    \RightLabel{\textsc{JoinI}$_2$}
    \UnaryInfC{$\tau \sub \rho \join \sigma$}
    \DisplayProof
 \end{center}

 \begin{prooftree}
  \AxiomC{$\tau \sub \rho$}
  \AxiomC{$\sigma \sub \rho$}
  \RightLabel{\textsc{JoinI}}
  \BinaryInfC{$\tau \join \sigma \sub \rho$}
\end{prooftree}

  % meet intro
  \begin{center}
    \AxiomC{$\tau \sub \rho$}
    \RightLabel{\textsc{MeetI}$_1$}
    \UnaryInfC{$\tau \meet \sigma \sub \rho$}
    \DisplayProof
    {\hskip.2in}
    \AxiomC{$\sigma \sub \rho$}
    \RightLabel{\textsc{MeetI}$_2$}
    \UnaryInfC{$\tau \meet \sigma \sub \rho$}
    \DisplayProof
 \end{center}

 \begin{prooftree}
  \AxiomC{$\tau \sub \rho$}
  \AxiomC{$\tau \sub \sigma$}
  \RightLabel{\textsc{MeetI}}
  \BinaryInfC{$\tau \sub \sigma \meet \rho$}
 \end{prooftree}

 \begin{prooftree}
  \AxiomC{$\tau' \sub \tau$}
  \AxiomC{$\sigma \sub \sigma'$}
  \RightLabel{\textsc{Func}}
  \BinaryInfC{$\tau \to \sigma \sub \tau' \to \sigma'$}
 \end{prooftree}

   % recursive types
   \begin{center}
    \AxiomC{}
    \RightLabel{\textsc{Rec}$_1$}
    \UnaryInfC{$\mu\rho.\tau \sub \tau [\mu\rho.\tau\ / \rho]$}
    \DisplayProof
    {\hskip.2in}
    \AxiomC{}
    \RightLabel{\textsc{Rec}$_2$}
    \UnaryInfC{$\tau[\mu\rho.\tau / \rho] \sub \mu\rho.\tau$}
    \DisplayProof
 \end{center}

 \caption{Subtyping rules}
 \label{fig:subtyping}
\end{figure}

 Using the \textsc{Trans} rule and the introduction rules, we can derive corresponding elimination rules:

 \begin{figure}[h]
 % join elim
 \begin{center}
  \AxiomC{$\tau \join \sigma \sub \rho$}
  \RightLabel{\textsc{JoinE}$_1$}
  \UnaryInfC{$\tau \sub \rho$}
  \DisplayProof
  {\hskip.2in}
  \AxiomC{$\tau \join \sigma \sub \rho$}
  \RightLabel{\textsc{JoinE}$_2$}
  \UnaryInfC{$\sigma \sub \rho$}
  \DisplayProof
\end{center}

\begin{prooftree}
  \AxiomC{$\tau \sub \sigma \join \rho$}
  \AxiomC{$\sigma \sub \upsilon$}
  \AxiomC{$\rho \sub \upsilon$}
  \RightLabel{\textsc{JoinE}}
  \TrinaryInfC{$\tau \sub \upsilon$}
 \end{prooftree}

% meet elim
\begin{center}
  \AxiomC{$\tau \sub \sigma \meet \rho$}
  \RightLabel{\textsc{MeetE}$_1$}
  \UnaryInfC{$\tau \sub \sigma$}
  \DisplayProof
  {\hskip.2in}
  \AxiomC{$\tau \sub \rho \meet \sigma$}
  \RightLabel{\textsc{MeetE}$_2$}
  \UnaryInfC{$\tau \sub \sigma$}
  \DisplayProof
\end{center}

\begin{center}
\AxiomC{$\tau \meet \sigma \sub \rho$}
\AxiomC{$\sigma \sub \upsilon$}
\RightLabel{\textsc{MeetE}}
\BinaryInfC{$\tau \sub \upsilon$}
\DisplayProof
{\hskip.2in}
\AxiomC{$\tau \meet \sigma \sub \rho$}
\AxiomC{$\tau \sub \upsilon$}
\RightLabel{\textsc{MeetE}}
\BinaryInfC{$\sigma \sub \upsilon$}
\DisplayProof
\end{center}


\caption{Derived subtyping rules}
\label{fig:subtypingDerived}
\end{figure}


Finally, we can add primitive rules (Fig. \ref{fig:prim-sub-rules}).
We want to express that every natural number is also an integer and therefore introduce a corresponding rule, as well as a rule for the singleton types $\Singleton{0}, \Singleton{1}, \Singleton{2}$ to be subtypes of $\Nat$:

\begin{figure}
\begin{center}
  \AxiomC{}
  \RightLabel{\textsc{NatPrim}}
  \UnaryInfC{$\Nat \sub \Int$}
  \DisplayProof
  {\hskip.2in}
  \AxiomC{}
  \RightLabel{\textsc{SingletonPrim}}
  \UnaryInfC{$\Singleton{0}, \Singleton{1}, \Singleton{2}, \dots \sub \Nat$}
  \DisplayProof
\end{center}

\caption{Primitve subtyping rules}
\label{fig:prim-sub-rules}
\end{figure}

% add function types

Liskov \cite{liskov} describes subtyping to adhere to the following substitution principle:

\begin{quote}
The intuitive idea of a subtype is one whose objects provide all the behavior of objects of another type (the supertype) plus something extra.
What is wanted here is something like the following substitution property:
If for each object [$e_1$] of type [$\tau$] there is an object [$e_2$] of type [$\sigma$] such that for all programs $P$ defined in terms of [$\sigma$],
the behavior of $P$ is unchanged when [$e_1$] is substituted for [$e_2$], then [$\tau$] is a subtype of [$\sigma$].
\end{quote}

In essence, given subtyping types are no longer disjoint but can be mixed together to display natural inclusion properties that we may expect.
E.g. every natural number is also an integer and therefore the type $\Nat$ of natural numbers is a subtype of $\Int$.

If we omit subtyping, we have to give explicit coercion functions (e.g. $\mathbf{coerce} : \Nat \to \Int$) whenever the expected type is more general than the given type.
Subtyping allows us to pass such more specific arguments in a more natural way and makes coercions implicit.

\section{Ad-hoc polymorphism}\label{sec:ad-hoc-polymorphism}
% overloading vs type classes
% paper by wadler

In some - mostly imperative - languages it is possible to simply overload functions (e.g. we may define $+$ both on integers and on float values, the correct implementation is then picked based on the argument type).
However, there is usually no way to express this in the type system of these languages.
Whether or not an operator is overloaded is a hidden implementation detail. % cite...

If our type system doesn't allow ad-hoc polymorphism it may seem neccessary to write verbose code for basic function with respect to every concrete type it should be used for.
An intuitive example for this (that is also the motivation for type classes in the original proposal) are arithmetic operators.
We simply cannot define $(+) : \Int \to \Int \to \Int$ and then also $(+) : \mathit{Float} \to \mathit{Float} \to \mathit{Float}$ in a different implementation, on which both types definetly rely on under the hood.
But these types have nonetheless something in common. Namely that they both stand for \emph{numerical} values, that hence support the usual arithmetic operations, like addition, multiplication, division and so on.

The idea of type classes is to generalise attributes of types with appropriate functions.
Type classes express the concept of ad-hoc polymorphism in the type system in a sensible  way.
Type class constraints are annotated in the type system. They refine a range of types which hold a specified property, i.e. implement a specific type class instance.
The class \mintinline{Haskell}|Num| in Haskell expects that we can implement a number of numerical functions for a type $\tau$ if it is ought to be a member of the \mintinline{Haskell}|Num| type class.

Shortened definition of the \mintinline{Haskell}|Num| type class in Haskell.
\footnote{As can be found in the default \texttt{Prelude}: \url{https://hackage.haskell.org/package/base-4.16.2.0/docs/Prelude.html\#t:Num}}

\begin{minted}{Haskell}
class  Num a  where
    (+), (-), (*) :: a -> a -> a
\end{minted}

An instance would look like:

\begin{minted}{Haskell}
instance  Num Int  where
    (+) = intAdd
    (-) = intMinus
    (*) = intMul
\end{minted}


In order to be able to reason about type classes, the instances in scope need to be \emph{coherent}, i.e. they need to be uniquely determined as will be shown in section \ref{sec:coherence}.
Incoherent instances can lead to unexpected behaviors in programs.
E.g. in Haskell sets are implemented as binary search trees relying on an ordering specified by the $Ord$ type class.
If this ordering is not uniquely determined, insert and delete operations may break as well which would make the library unusable. \cite{Kilpatrick2019-cy}

% ???
In the end, this enables us to use elaborate concepts such as functors and monads to reason about programs.

\cite{wadlerblott}

\section{Relation between different forms of Subtyping}\label{sec:relations}

The different forms of subtyping just discussed are not unrelated.

We can understand both parametric and ad-hoc polymorhism as a form of subtyping.
E.g. given both parametric polymorphism and subtyping the $\mathbf{const}$ function can be typeable both by
$\mathbf{const} : \forall \alpha \beta. \alpha \to \beta \to \beta$ and $\mathbf{const} : \forall \alpha. \top \to \alpha \to \alpha$.
Now there are two ways to substitute any type for the first argument of the function.

Similarily, the hierarchy of type classes can express a similar relationship exhibited by subtyping.
E.g. the \mintinline{Haskell}{Fractional} type class is a subclass of the type class \mintinline{Haskell}{Num}.
Similarily with subtyping we can define a type $\mathit{Fractional}$ as the union of all types that are instances of \mintinline{Haskell}{Fractional} representing all fractional numbers and make it a subtype of $\mathit{Number}$ represented as the union of all types that stand for numbers.

A way to model type classes solely with subtyping can be to define the overloaded type class methods directly.
So instead of a type class method $f : \forall \alpha. C \alpha \Rightarrow \tau[\alpha]$ and instance $C \alpha_1, \dots, C \alpha_n$,
we could directly define $f$ using union types for covariant type classes as $f : \forall \alpha_1,\dots,\alpha_n. \tau[\alpha_1 \join \dots \join \alpha_n]$.
Dually we could do the same using intersection types for contravariant type classes.
The obvious drawback would be that such functions are non-modular, i.e. they can only be defined at one point in the program.
Unlike instances the definition cannot be expanded in submodules.

If we make instances explicit (like in ML-modules) type class overloading can be implemented solely with passing specific instance definitions.
This is no coincidence as dictionary passing is a typical way of implementing type classes as shown in section \ref{sec:dictionaryPassing}.

\subsection{Coherence}\label{sec:coherence}
% for each type there t may be globally at most one instance C t defined
% discuss overlapping instances
% can already be tricky in a modular system
% more challenging with subtyping

Even though the general concept of type classes introduces a general meaning for each type class.
The evaluation still strongly depends on implementation details found in specific instances.
For example, for the $\mathit{Ord}$ type class we may choose to implement the ordering in ascending or descending order.
It is therefore crucial, that for each type the corresponding instance - if it exists - is uniquely determined by the type.

Reynolds \cite{reynolds_coherence} describes the issue of coherence as follows:

\begin{quote}
    When a programming language has a sufficiently rich type structure, there can be more than one proof of the same
    typing judgment; potentially this can lead to semantic ambiguity since the semantics of a typed language is a function
    of such proofs. When no such ambiguity arises, we say that the language is coherent.
\end{quote}

When talking about predicates on types we have to enforce that if $\Phi(\tau)$ holds for some predicate $\Phi$ on some type $\tau$,
then all evidence for this judgement has to be in some sense equivalent.

For type classes, this means that no two instances should be able to be resolved for the application of a type class constraint on the same type.
A rather obvious example would be to define two different instances for the same type.
For example one instance of \mintinline{Haskell}{Ord Int}, one with ascending and one with descending order.

The ambiguity arises as soon as we make use of these instances and it is no longer clear which one should be picked for evaluation.
Data structures relying on coherent instances such as the module \mintinline{Haskell}{Data.Set} in Haskell may even exhibit faulty behavior if different implementations are being used. \cite{Kilpatrick2019-cy}

More surprisingly type class coherence is already violated for overlapping instances.
As part of the standard prelude we find both \mintinline{Haskell}{instance Show a => Show [a]} and \mintinline{Haskell}{instance Show String}
(with \mintinline{Haskell}{String} being a type synonym for \mintinline{Haskell}{[Char]}).
The $\mathit{Show}$ instance for Strings differs from the more general instance for lists.
Even though there arises an ambiguity, the language extension \emph{Overlapping Instances} enforces higher precedence for the $Show$ instance of Strings.
Therefore, the instance for lists will not be resolved for lists of $Chars$, i.e. $Strings$.

Incoherent programs should generally not be typeable.
One example, also mentioned in the Haskell 98 report \cite{Haskell98} is this short program which simply reads a string to a data type and then converts it back to string without specifying which data type is being used:

\begin{minted}{Haskell}
    f :: String -> String
    f str = let x = read str in show x
\end{minted}

There may be multiple types that satisfy the type class constraints.
The specific implementation of \mintinline{Haskell}{show :: forall a. (Show a) => a -> String} and \mintinline{Haskell}{read :: forall a. (Read a) => String -> a} is therefore unknown.

In the Haskell98 standard, type class coherence is guaranteed by the syntactical equivalence of resolved instances.
For each Haskell type there may be at most one instance defined for each type class.


\subsection{Superclasses}

Superclasses impose additional constraints on type classes.
If $sup$ is a superclass of $sub$, then if we want to implement an instance of $sub \;\tau$, then there needs to exist an instance for $sup \;\tau$ as well.
Usually this is done because the subclass relies on an implementation of the superclass or because the superclass proves a property about the type.

E.g. the type class \mintinline{Haskell}{Eq} in Haskell is a superclass of \mintinline{Haskell}{Ord}, written \mintinline{Haskell}{Eq a => Ord a}.
This means that for each type that we want to define an ordering for already needs to have equality defined on.

For example, given an instance for \mintinline{Haskell}{Ord (Maybe a)} we can then derive that an instance for \mintinline{Haskell}{Eq a} has to exist.
As shown in the diagram, we can take different paths to do so but type class coherence guarantees that no matter which path we choose to resolve the instance, we will always find \emph{the same} instance.
In Haskell98 type class coherence guarantees that all such diagrams commute.
So even if there may be different ways to resolve type class constraints, all of them preserve the same semantics.

\begin{tikzcd}
    &  & \mintinline{Haskell}|Ord (Maybe a)| \arrow[llddd, "{\footnotesize\mintinline{Haskell}|class Eq a => Ord a|}"'] \arrow[rrddd, "{\footnotesize\mintinline{Haskell}|instance Ord a => Ord (Maybe a)|}"] &  &                            \\
    &  &                                &  &                            \\
    &  &                                &  &                            \\
    \mintinline{Haskell}|Eq (Maybe a)| \arrow[rrddd, "{\footnotesize\mintinline{Haskell}|instance Eq a => Eq (Maybe a)|}"'] &  &                                &  & \mintinline{Haskell}|Ord a| \arrow[llddd, "{\footnotesize \mintinline{Haskell}|class Eq a => Ord a|}"] \\
    &  &                                &  &                            \\
    &  &                                &  &                            \\
    &  & \mintinline{Haskell}|Eq a|                  &  &                           
\end{tikzcd}

Even though there are multiple ways to derive an instance for \mintinline{Haskell}|Eq a| from an instance of \mintinline{Haskell}|Ord (Maybe a)|, the derived instance has to be uniquely determined.
Since the diagram commutes, there has to be exactly one instance for \mintinline{Haskell}|Eq a|.

\subsection{How to ensure coherence}

There are several ways to ensure type class coherence.
The easiest one can also be found in Haskell98.
Here, overlapping or otherwise ambiguous instances are simply not allowed to be declared in the same namespace.
% The report only states: 'A type may not be declared as an instance of a particular class more than once in the program.'

Another possibility somewhat alike ML-modules are named instances.
They have the advantage that we can explicitly use instances and therefore it is allowed to have overlapping instances in scope.
The drawback however, is that we lose true overloading because that way we always \emph{have to} name instances explicitly to avoid name clashes.

The latest proposal are instance chains which make the order in which instances are checked explicit, thus avoiding the ambuigity. \cite{morris2010instance}
These are supported in Haskell to some degree with the \mintinline{Haskell}{Overlaps} pragma.
